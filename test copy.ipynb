{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbdc48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./yolov5-env/lib/python3.12/site-packages (8.3.107)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./yolov5-env/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./yolov5-env/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./yolov5-env/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./yolov5-env/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./yolov5-env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./yolov5-env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./yolov5-env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./yolov5-env/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: networkx in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./yolov5-env/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./yolov5-env/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./yolov5-env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./yolov5-env/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4356ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/ujjwalraj/Desktop/Ewaste/image.jpg: 640x640 1 tv, 81.7ms\n",
      "Speed: 1.1ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# you can use yolov8s.pt, yolov8m.pt, etc.\u001b[39;00m\n\u001b[32m      4\u001b[39m results = model(\u001b[33m\"\u001b[39m\u001b[33mimage.jpg\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Inference on an image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m()  \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n\u001b[32m      6\u001b[39m results.save()  \u001b[38;5;66;03m# Save results to 'runs/detect/predict'\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # you can use yolov8s.pt, yolov8m.pt, etc.\n",
    "results = model(\"image.jpg\")  # Inference on an image\n",
    "results.show()  # Visualize results\n",
    "results.save()  # Save results to 'runs/detect/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b326144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/ujjwalraj/Desktop/Ewaste/image.jpg: 640x640 1 tv, 103.4ms\n",
      "Speed: 3.6ms preprocess, 103.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"image.jpg\")     # This returns a list\n",
    "results[0].show()                # Access the first result and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f753863f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 118.2ms\n",
      "Speed: 2.6ms preprocess, 118.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 192.9ms\n",
      "Speed: 2.0ms preprocess, 192.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.5ms\n",
      "Speed: 2.2ms preprocess, 100.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 101.8ms\n",
      "Speed: 1.4ms preprocess, 101.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 195.2ms\n",
      "Speed: 1.6ms preprocess, 195.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.0ms\n",
      "Speed: 1.2ms preprocess, 102.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.6ms\n",
      "Speed: 1.4ms preprocess, 100.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.8ms\n",
      "Speed: 1.2ms preprocess, 106.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.0ms\n",
      "Speed: 1.2ms preprocess, 109.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.9ms\n",
      "Speed: 1.4ms preprocess, 99.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.6ms\n",
      "Speed: 1.3ms preprocess, 104.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.8ms\n",
      "Speed: 1.7ms preprocess, 99.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.3ms\n",
      "Speed: 1.6ms preprocess, 94.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 86.6ms\n",
      "Speed: 1.1ms preprocess, 86.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.2ms\n",
      "Speed: 1.5ms preprocess, 85.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.4ms\n",
      "Speed: 1.1ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.8ms\n",
      "Speed: 1.6ms preprocess, 87.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.8ms\n",
      "Speed: 3.5ms preprocess, 86.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.3ms\n",
      "Speed: 1.6ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.1ms\n",
      "Speed: 1.4ms preprocess, 82.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.6ms\n",
      "Speed: 1.3ms preprocess, 116.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 93.6ms\n",
      "Speed: 1.3ms preprocess, 93.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.3ms\n",
      "Speed: 1.4ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.3ms\n",
      "Speed: 1.3ms preprocess, 104.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.9ms\n",
      "Speed: 1.6ms preprocess, 90.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.0ms\n",
      "Speed: 1.3ms preprocess, 100.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.7ms\n",
      "Speed: 1.3ms preprocess, 85.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.7ms\n",
      "Speed: 1.3ms preprocess, 88.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.7ms\n",
      "Speed: 1.1ms preprocess, 103.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.9ms\n",
      "Speed: 1.8ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.8ms\n",
      "Speed: 1.6ms preprocess, 107.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.2ms\n",
      "Speed: 1.4ms preprocess, 84.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.9ms\n",
      "Speed: 1.2ms preprocess, 70.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 1.1ms preprocess, 71.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.1ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.2ms\n",
      "Speed: 1.2ms preprocess, 72.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.2ms\n",
      "Speed: 1.2ms preprocess, 74.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 73.6ms\n",
      "Speed: 1.1ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 73.2ms\n",
      "Speed: 1.0ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.8ms\n",
      "Speed: 1.1ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 77.1ms\n",
      "Speed: 1.2ms preprocess, 77.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 75.6ms\n",
      "Speed: 1.6ms preprocess, 75.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.8ms\n",
      "Speed: 1.3ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.7ms\n",
      "Speed: 1.4ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.8ms\n",
      "Speed: 1.2ms preprocess, 71.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 77.0ms\n",
      "Speed: 1.3ms preprocess, 77.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.4ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.1ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 78.0ms\n",
      "Speed: 1.1ms preprocess, 78.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 1.3ms preprocess, 81.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Speed: 1.0ms preprocess, 77.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 1.1ms preprocess, 71.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 82.4ms\n",
      "Speed: 1.2ms preprocess, 82.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 79.9ms\n",
      "Speed: 1.3ms preprocess, 79.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.1ms\n",
      "Speed: 1.0ms preprocess, 72.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.6ms\n",
      "Speed: 1.4ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.7ms\n",
      "Speed: 1.2ms preprocess, 72.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.9ms\n",
      "Speed: 1.2ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.1ms\n",
      "Speed: 1.0ms preprocess, 72.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.4ms\n",
      "Speed: 1.4ms preprocess, 73.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 77.4ms\n",
      "Speed: 1.3ms preprocess, 77.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.4ms\n",
      "Speed: 1.3ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 77.6ms\n",
      "Speed: 1.1ms preprocess, 77.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 71.2ms\n",
      "Speed: 1.2ms preprocess, 71.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 70.0ms\n",
      "Speed: 1.4ms preprocess, 70.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.5ms\n",
      "Speed: 1.2ms preprocess, 75.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.7ms\n",
      "Speed: 1.4ms preprocess, 75.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bottle, 80.0ms\n",
      "Speed: 1.1ms preprocess, 80.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.8ms\n",
      "Speed: 1.5ms preprocess, 72.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 71.6ms\n",
      "Speed: 1.1ms preprocess, 71.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 74.0ms\n",
      "Speed: 1.1ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.2ms\n",
      "Speed: 1.4ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 1.0ms preprocess, 71.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 84.0ms\n",
      "Speed: 11.4ms preprocess, 84.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.1ms\n",
      "Speed: 1.1ms preprocess, 73.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 0.9ms preprocess, 78.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.0ms\n",
      "Speed: 1.3ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.0ms\n",
      "Speed: 1.0ms preprocess, 73.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.4ms\n",
      "Speed: 1.4ms preprocess, 73.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.1ms\n",
      "Speed: 1.2ms preprocess, 71.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 1.1ms preprocess, 73.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 1.3ms preprocess, 72.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.9ms\n",
      "Speed: 1.3ms preprocess, 71.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.6ms\n",
      "Speed: 1.1ms preprocess, 72.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 79.6ms\n",
      "Speed: 1.0ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 80.4ms\n",
      "Speed: 1.0ms preprocess, 80.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.2ms\n",
      "Speed: 1.2ms preprocess, 78.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.5ms\n",
      "Speed: 1.2ms preprocess, 71.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.3ms\n",
      "Speed: 0.9ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.7ms\n",
      "Speed: 1.2ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.4ms\n",
      "Speed: 1.3ms preprocess, 72.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.6ms\n",
      "Speed: 1.3ms preprocess, 71.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.1ms\n",
      "Speed: 1.0ms preprocess, 71.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 74.1ms\n",
      "Speed: 0.9ms preprocess, 74.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.8ms\n",
      "Speed: 0.9ms preprocess, 77.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 84.2ms\n",
      "Speed: 1.5ms preprocess, 84.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 1 microwave, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.9ms\n",
      "Speed: 1.2ms preprocess, 75.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 81.6ms\n",
      "Speed: 1.2ms preprocess, 81.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 91.5ms\n",
      "Speed: 1.3ms preprocess, 91.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 1 cell phone, 75.4ms\n",
      "Speed: 1.2ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 81.3ms\n",
      "Speed: 1.0ms preprocess, 81.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 77.6ms\n",
      "Speed: 1.6ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 77.3ms\n",
      "Speed: 1.3ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 71.8ms\n",
      "Speed: 1.3ms preprocess, 71.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 75.5ms\n",
      "Speed: 1.2ms preprocess, 75.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 73.0ms\n",
      "Speed: 1.3ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.1ms\n",
      "Speed: 1.2ms preprocess, 73.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 73.1ms\n",
      "Speed: 1.2ms preprocess, 73.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 1.0ms preprocess, 72.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.8ms\n",
      "Speed: 1.1ms preprocess, 71.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 1.0ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.1ms\n",
      "Speed: 1.2ms preprocess, 73.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.8ms\n",
      "Speed: 1.1ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 1.0ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.2ms\n",
      "Speed: 1.5ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 1.3ms preprocess, 75.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.9ms\n",
      "Speed: 1.0ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.4ms\n",
      "Speed: 1.0ms preprocess, 73.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 1.1ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.5ms\n",
      "Speed: 1.3ms preprocess, 73.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 0.9ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 72.3ms\n",
      "Speed: 1.0ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 74.0ms\n",
      "Speed: 1.2ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.3ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 71.6ms\n",
      "Speed: 1.0ms preprocess, 71.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 74.1ms\n",
      "Speed: 1.4ms preprocess, 74.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 77.3ms\n",
      "Speed: 1.1ms preprocess, 77.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 77.9ms\n",
      "Speed: 1.7ms preprocess, 77.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 72.6ms\n",
      "Speed: 1.1ms preprocess, 72.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.0ms\n",
      "Speed: 1.2ms preprocess, 74.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 74.5ms\n",
      "Speed: 1.1ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 74.2ms\n",
      "Speed: 1.1ms preprocess, 74.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.6ms\n",
      "Speed: 1.3ms preprocess, 75.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.2ms\n",
      "Speed: 1.2ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.9ms\n",
      "Speed: 1.3ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.5ms\n",
      "Speed: 0.9ms preprocess, 75.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 216.5ms\n",
      "Speed: 1.3ms preprocess, 216.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 125.3ms\n",
      "Speed: 1.4ms preprocess, 125.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.4ms\n",
      "Speed: 1.7ms preprocess, 94.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 80.8ms\n",
      "Speed: 1.2ms preprocess, 80.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 85.1ms\n",
      "Speed: 1.3ms preprocess, 85.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.9ms\n",
      "Speed: 1.2ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.1ms\n",
      "Speed: 1.1ms preprocess, 75.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.2ms\n",
      "Speed: 1.1ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.2ms\n",
      "Speed: 1.1ms preprocess, 71.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.6ms\n",
      "Speed: 1.4ms preprocess, 72.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.6ms\n",
      "Speed: 1.1ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.4ms\n",
      "Speed: 1.1ms preprocess, 75.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 1.1ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.1ms\n",
      "Speed: 1.2ms preprocess, 74.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.6ms\n",
      "Speed: 1.4ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.7ms\n",
      "Speed: 1.1ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.1ms\n",
      "Speed: 1.2ms preprocess, 76.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.3ms\n",
      "Speed: 1.3ms preprocess, 76.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.3ms\n",
      "Speed: 1.3ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.2ms\n",
      "Speed: 1.1ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.6ms\n",
      "Speed: 0.9ms preprocess, 72.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.7ms\n",
      "Speed: 1.3ms preprocess, 71.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.6ms\n",
      "Speed: 1.3ms preprocess, 71.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.6ms\n",
      "Speed: 1.1ms preprocess, 70.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 1.2ms preprocess, 75.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.7ms\n",
      "Speed: 1.2ms preprocess, 84.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 1.2ms preprocess, 76.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 69.9ms\n",
      "Speed: 1.6ms preprocess, 69.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.6ms\n",
      "Speed: 0.9ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.5ms\n",
      "Speed: 1.4ms preprocess, 73.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.1ms\n",
      "Speed: 1.2ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.9ms\n",
      "Speed: 1.1ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.4ms\n",
      "Speed: 1.2ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.5ms\n",
      "Speed: 1.4ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.2ms\n",
      "Speed: 1.1ms preprocess, 77.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 92.0ms\n",
      "Speed: 1.1ms preprocess, 92.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.3ms\n",
      "Speed: 2.5ms preprocess, 77.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 79.3ms\n",
      "Speed: 1.0ms preprocess, 79.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 81.1ms\n",
      "Speed: 1.2ms preprocess, 81.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.1ms\n",
      "Speed: 1.1ms preprocess, 71.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.0ms\n",
      "Speed: 1.3ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 84.7ms\n",
      "Speed: 1.6ms preprocess, 84.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.6ms\n",
      "Speed: 1.1ms preprocess, 77.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.5ms\n",
      "Speed: 1.1ms preprocess, 73.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.9ms\n",
      "Speed: 1.3ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 73.3ms\n",
      "Speed: 1.2ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 78.6ms\n",
      "Speed: 1.3ms preprocess, 78.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.5ms\n",
      "Speed: 1.2ms preprocess, 75.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.4ms\n",
      "Speed: 1.2ms preprocess, 73.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.1ms\n",
      "Speed: 1.2ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.8ms\n",
      "Speed: 1.5ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.9ms\n",
      "Speed: 29.0ms preprocess, 83.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.8ms\n",
      "Speed: 1.6ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.9ms\n",
      "Speed: 1.3ms preprocess, 70.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.2ms\n",
      "Speed: 1.2ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.0ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.2ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 70.3ms\n",
      "Speed: 1.3ms preprocess, 70.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 89.1ms\n",
      "Speed: 1.3ms preprocess, 89.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 78.8ms\n",
      "Speed: 1.3ms preprocess, 78.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 86.9ms\n",
      "Speed: 1.2ms preprocess, 86.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.7ms\n",
      "Speed: 1.4ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.8ms\n",
      "Speed: 1.5ms preprocess, 73.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 73.1ms\n",
      "Speed: 1.4ms preprocess, 73.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.7ms\n",
      "Speed: 1.1ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 70.9ms\n",
      "Speed: 1.4ms preprocess, 70.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.9ms\n",
      "Speed: 1.1ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.4ms preprocess, 72.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.3ms\n",
      "Speed: 1.3ms preprocess, 73.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.9ms\n",
      "Speed: 1.1ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.2ms\n",
      "Speed: 1.3ms preprocess, 77.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.1ms\n",
      "Speed: 1.2ms preprocess, 72.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.3ms\n",
      "Speed: 1.1ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.9ms\n",
      "Speed: 1.2ms preprocess, 72.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.3ms preprocess, 72.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.1ms\n",
      "Speed: 1.2ms preprocess, 76.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 79.5ms\n",
      "Speed: 1.2ms preprocess, 79.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.3ms\n",
      "Speed: 1.4ms preprocess, 75.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.3ms preprocess, 74.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 80.9ms\n",
      "Speed: 1.3ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 82.2ms\n",
      "Speed: 1.8ms preprocess, 82.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.7ms\n",
      "Speed: 1.3ms preprocess, 74.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.0ms\n",
      "Speed: 1.4ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 85.7ms\n",
      "Speed: 1.1ms preprocess, 85.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.1ms\n",
      "Speed: 1.1ms preprocess, 76.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.9ms\n",
      "Speed: 1.1ms preprocess, 71.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 70.0ms\n",
      "Speed: 1.1ms preprocess, 70.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.1ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.5ms\n",
      "Speed: 1.0ms preprocess, 72.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.5ms\n",
      "Speed: 0.9ms preprocess, 77.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.2ms\n",
      "Speed: 1.7ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.2ms\n",
      "Speed: 0.9ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 1.1ms preprocess, 73.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.0ms\n",
      "Speed: 1.5ms preprocess, 75.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.8ms\n",
      "Speed: 0.9ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.3ms preprocess, 72.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.5ms\n",
      "Speed: 1.3ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.0ms\n",
      "Speed: 1.3ms preprocess, 73.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 72.4ms\n",
      "Speed: 1.4ms preprocess, 72.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.2ms\n",
      "Speed: 1.0ms preprocess, 72.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 73.3ms\n",
      "Speed: 1.2ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 72.3ms\n",
      "Speed: 1.2ms preprocess, 72.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.0ms\n",
      "Speed: 1.1ms preprocess, 75.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.6ms\n",
      "Speed: 1.2ms preprocess, 72.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.7ms\n",
      "Speed: 1.2ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 1 microwave, 73.9ms\n",
      "Speed: 1.0ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.1ms\n",
      "Speed: 1.2ms preprocess, 77.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 1.4ms preprocess, 72.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.3ms\n",
      "Speed: 1.4ms preprocess, 73.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.8ms\n",
      "Speed: 1.3ms preprocess, 72.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.2ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.3ms\n",
      "Speed: 1.4ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.1ms\n",
      "Speed: 1.1ms preprocess, 77.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.7ms\n",
      "Speed: 1.1ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.5ms preprocess, 72.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 85.1ms\n",
      "Speed: 1.3ms preprocess, 85.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.2ms\n",
      "Speed: 1.7ms preprocess, 81.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 1.3ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 70.3ms\n",
      "Speed: 1.1ms preprocess, 70.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 74.0ms\n",
      "Speed: 1.0ms preprocess, 74.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.7ms\n",
      "Speed: 1.6ms preprocess, 72.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.4ms\n",
      "Speed: 1.1ms preprocess, 72.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 74.1ms\n",
      "Speed: 1.0ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 71.9ms\n",
      "Speed: 1.0ms preprocess, 71.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 76.3ms\n",
      "Speed: 1.2ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.3ms\n",
      "Speed: 1.3ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 70.4ms\n",
      "Speed: 1.1ms preprocess, 70.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 77.7ms\n",
      "Speed: 1.1ms preprocess, 77.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.5ms\n",
      "Speed: 1.0ms preprocess, 73.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 1.0ms preprocess, 71.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.5ms\n",
      "Speed: 1.4ms preprocess, 85.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.6ms\n",
      "Speed: 2.0ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 1.3ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.4ms\n",
      "Speed: 2.4ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.8ms\n",
      "Speed: 1.1ms preprocess, 72.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 1.1ms preprocess, 76.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 72.7ms\n",
      "Speed: 1.2ms preprocess, 72.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.4ms\n",
      "Speed: 0.9ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.4ms\n",
      "Speed: 1.2ms preprocess, 73.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 1.0ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 69.5ms\n",
      "Speed: 1.0ms preprocess, 69.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.5ms\n",
      "Speed: 1.3ms preprocess, 73.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.7ms\n",
      "Speed: 1.3ms preprocess, 75.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.5ms\n",
      "Speed: 1.2ms preprocess, 77.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.8ms\n",
      "Speed: 1.0ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.8ms\n",
      "Speed: 1.2ms preprocess, 71.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 75.2ms\n",
      "Speed: 1.6ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.5ms\n",
      "Speed: 1.3ms preprocess, 75.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.2ms\n",
      "Speed: 1.0ms preprocess, 72.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.3ms\n",
      "Speed: 1.1ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.1ms preprocess, 72.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.1ms preprocess, 74.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.7ms\n",
      "Speed: 1.4ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.4ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.8ms\n",
      "Speed: 1.0ms preprocess, 71.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.4ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 73.6ms\n",
      "Speed: 1.4ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.3ms\n",
      "Speed: 1.2ms preprocess, 71.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.1ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.0ms\n",
      "Speed: 1.0ms preprocess, 72.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.7ms\n",
      "Speed: 1.0ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.3ms\n",
      "Speed: 1.2ms preprocess, 72.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 82.5ms\n",
      "Speed: 1.1ms preprocess, 82.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 74.9ms\n",
      "Speed: 1.4ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 130.5ms\n",
      "Speed: 1.6ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 84.9ms\n",
      "Speed: 1.1ms preprocess, 84.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 91.2ms\n",
      "Speed: 1.1ms preprocess, 91.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 87.5ms\n",
      "Speed: 1.3ms preprocess, 87.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.9ms\n",
      "Speed: 1.9ms preprocess, 73.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.2ms\n",
      "Speed: 1.5ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.1ms\n",
      "Speed: 1.1ms preprocess, 74.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.2ms\n",
      "Speed: 1.0ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.4ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.3ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 75.3ms\n",
      "Speed: 1.0ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 83.8ms\n",
      "Speed: 1.3ms preprocess, 83.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.4ms\n",
      "Speed: 1.1ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.0ms\n",
      "Speed: 1.3ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 103.0ms\n",
      "Speed: 1.4ms preprocess, 103.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 78.8ms\n",
      "Speed: 1.0ms preprocess, 78.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.9ms\n",
      "Speed: 1.0ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 70.5ms\n",
      "Speed: 1.2ms preprocess, 70.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.7ms\n",
      "Speed: 1.4ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.0ms\n",
      "Speed: 1.2ms preprocess, 74.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 74.5ms\n",
      "Speed: 1.1ms preprocess, 74.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.0ms\n",
      "Speed: 1.2ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.2ms\n",
      "Speed: 1.0ms preprocess, 74.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 73.6ms\n",
      "Speed: 1.2ms preprocess, 73.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 70.0ms\n",
      "Speed: 1.2ms preprocess, 70.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.4ms\n",
      "Speed: 1.0ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 77.3ms\n",
      "Speed: 1.2ms preprocess, 77.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.5ms\n",
      "Speed: 1.1ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.4ms\n",
      "Speed: 1.1ms preprocess, 75.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.9ms\n",
      "Speed: 1.3ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.3ms preprocess, 76.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.2ms\n",
      "Speed: 1.3ms preprocess, 78.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 73.9ms\n",
      "Speed: 1.1ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 1.0ms preprocess, 76.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.7ms\n",
      "Speed: 1.2ms preprocess, 76.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.8ms\n",
      "Speed: 1.2ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 75.2ms\n",
      "Speed: 1.4ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 1.3ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.2ms\n",
      "Speed: 1.1ms preprocess, 71.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.7ms\n",
      "Speed: 1.5ms preprocess, 73.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.0ms\n",
      "Speed: 1.2ms preprocess, 76.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.5ms\n",
      "Speed: 1.1ms preprocess, 72.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.3ms\n",
      "Speed: 1.2ms preprocess, 72.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 87.8ms\n",
      "Speed: 1.4ms preprocess, 87.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.6ms\n",
      "Speed: 2.3ms preprocess, 76.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.2ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 83.4ms\n",
      "Speed: 1.7ms preprocess, 83.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 88.6ms\n",
      "Speed: 1.3ms preprocess, 88.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 84.1ms\n",
      "Speed: 1.6ms preprocess, 84.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 82.2ms\n",
      "Speed: 1.2ms preprocess, 82.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.3ms\n",
      "Speed: 1.3ms preprocess, 76.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 359.9ms\n",
      "Speed: 1.3ms preprocess, 359.9ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 408.2ms\n",
      "Speed: 11.5ms preprocess, 408.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 122.6ms\n",
      "Speed: 1.9ms preprocess, 122.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 96.2ms\n",
      "Speed: 1.1ms preprocess, 96.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 85.4ms\n",
      "Speed: 1.3ms preprocess, 85.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 87.4ms\n",
      "Speed: 1.2ms preprocess, 87.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 86.9ms\n",
      "Speed: 1.0ms preprocess, 86.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 95.7ms\n",
      "Speed: 1.4ms preprocess, 95.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 97.0ms\n",
      "Speed: 1.1ms preprocess, 97.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 111.0ms\n",
      "Speed: 1.2ms preprocess, 111.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 94.5ms\n",
      "Speed: 1.3ms preprocess, 94.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 95.2ms\n",
      "Speed: 1.4ms preprocess, 95.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 105.8ms\n",
      "Speed: 1.2ms preprocess, 105.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 1 microwave, 84.9ms\n",
      "Speed: 1.3ms preprocess, 84.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 84.9ms\n",
      "Speed: 1.2ms preprocess, 84.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 85.7ms\n",
      "Speed: 1.4ms preprocess, 85.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 84.5ms\n",
      "Speed: 1.1ms preprocess, 84.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 cell phone, 86.5ms\n",
      "Speed: 1.2ms preprocess, 86.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 82.1ms\n",
      "Speed: 1.3ms preprocess, 82.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 70.9ms\n",
      "Speed: 1.5ms preprocess, 70.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.0ms\n",
      "Speed: 1.7ms preprocess, 75.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.6ms\n",
      "Speed: 1.2ms preprocess, 74.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.3ms preprocess, 74.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.6ms\n",
      "Speed: 1.1ms preprocess, 73.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.6ms\n",
      "Speed: 1.1ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.9ms\n",
      "Speed: 1.3ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 81.6ms\n",
      "Speed: 1.0ms preprocess, 81.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 79.4ms\n",
      "Speed: 1.1ms preprocess, 79.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.2ms\n",
      "Speed: 1.1ms preprocess, 72.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.8ms\n",
      "Speed: 1.0ms preprocess, 75.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 266.2ms\n",
      "Speed: 1.2ms preprocess, 266.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 86.0ms\n",
      "Speed: 1.2ms preprocess, 86.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 80.6ms\n",
      "Speed: 1.2ms preprocess, 80.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 79.8ms\n",
      "Speed: 1.1ms preprocess, 79.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 79.0ms\n",
      "Speed: 1.4ms preprocess, 79.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 71.6ms\n",
      "Speed: 1.1ms preprocess, 71.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.2ms\n",
      "Speed: 1.4ms preprocess, 76.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.2ms\n",
      "Speed: 1.3ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 74.5ms\n",
      "Speed: 1.0ms preprocess, 74.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 72.9ms\n",
      "Speed: 1.0ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 76.4ms\n",
      "Speed: 1.1ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 73.5ms\n",
      "Speed: 1.1ms preprocess, 73.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 2.9ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.0ms\n",
      "Speed: 1.1ms preprocess, 77.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.6ms\n",
      "Speed: 1.0ms preprocess, 76.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.9ms\n",
      "Speed: 1.2ms preprocess, 73.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 71.9ms\n",
      "Speed: 1.3ms preprocess, 71.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 74.1ms\n",
      "Speed: 1.1ms preprocess, 74.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.2ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 1.3ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 1.4ms preprocess, 72.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 1.4ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.5ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 1.6ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.9ms\n",
      "Speed: 1.2ms preprocess, 74.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.2ms preprocess, 72.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.6ms\n",
      "Speed: 1.4ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.0ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.2ms\n",
      "Speed: 1.1ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.9ms\n",
      "Speed: 1.3ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.4ms\n",
      "Speed: 1.6ms preprocess, 75.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.5ms\n",
      "Speed: 1.4ms preprocess, 72.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 1.7ms preprocess, 74.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.1ms\n",
      "Speed: 1.2ms preprocess, 80.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 1.2ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.5ms\n",
      "Speed: 1.1ms preprocess, 73.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.2ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 1.2ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.1ms\n",
      "Speed: 1.1ms preprocess, 74.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 tv, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.1ms\n",
      "Speed: 1.2ms preprocess, 106.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 1.4ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.1ms\n",
      "Speed: 1.2ms preprocess, 96.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 82.1ms\n",
      "Speed: 1.5ms preprocess, 82.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.9ms\n",
      "Speed: 1.4ms preprocess, 72.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.6ms\n",
      "Speed: 1.7ms preprocess, 89.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 4.7ms preprocess, 77.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.6ms\n",
      "Speed: 1.2ms preprocess, 73.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.2ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 1.1ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.1ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 1.5ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.9ms\n",
      "Speed: 1.4ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.4ms\n",
      "Speed: 1.2ms preprocess, 89.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.8ms\n",
      "Speed: 1.1ms preprocess, 72.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.0ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 1.1ms preprocess, 73.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.6ms\n",
      "Speed: 1.4ms preprocess, 72.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.6ms\n",
      "Speed: 1.1ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 1.1ms preprocess, 76.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 1.1ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.7ms\n",
      "Speed: 1.1ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 1.1ms preprocess, 73.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.0ms\n",
      "Speed: 1.2ms preprocess, 73.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.3ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.3ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 1.2ms preprocess, 78.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.3ms preprocess, 73.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.7ms\n",
      "Speed: 1.0ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.0ms\n",
      "Speed: 1.2ms preprocess, 75.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.1ms\n",
      "Speed: 1.2ms preprocess, 72.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 71.7ms\n",
      "Speed: 1.3ms preprocess, 71.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.5ms\n",
      "Speed: 1.4ms preprocess, 75.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 78.8ms\n",
      "Speed: 1.2ms preprocess, 78.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.7ms\n",
      "Speed: 1.6ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.6ms\n",
      "Speed: 1.1ms preprocess, 73.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.0ms\n",
      "Speed: 1.0ms preprocess, 74.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.6ms\n",
      "Speed: 1.2ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.2ms\n",
      "Speed: 1.1ms preprocess, 74.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 72.8ms\n",
      "Speed: 1.2ms preprocess, 72.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.5ms\n",
      "Speed: 1.1ms preprocess, 73.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.5ms\n",
      "Speed: 1.0ms preprocess, 73.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.6ms\n",
      "Speed: 1.3ms preprocess, 71.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 71.6ms\n",
      "Speed: 1.1ms preprocess, 71.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 73.8ms\n",
      "Speed: 1.5ms preprocess, 73.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.4ms\n",
      "Speed: 1.5ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.9ms\n",
      "Speed: 1.7ms preprocess, 93.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.6ms\n",
      "Speed: 7.7ms preprocess, 82.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.6ms\n",
      "Speed: 1.2ms preprocess, 88.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.9ms\n",
      "Speed: 1.2ms preprocess, 72.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.0ms\n",
      "Speed: 1.5ms preprocess, 91.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 72.5ms\n",
      "Speed: 1.3ms preprocess, 72.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 1.3ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 73.7ms\n",
      "Speed: 1.4ms preprocess, 73.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.2ms\n",
      "Speed: 1.1ms preprocess, 72.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.7ms\n",
      "Speed: 1.0ms preprocess, 74.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 81.2ms\n",
      "Speed: 1.5ms preprocess, 81.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 1.2ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.7ms\n",
      "Speed: 1.3ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.9ms\n",
      "Speed: 1.5ms preprocess, 74.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.6ms\n",
      "Speed: 1.1ms preprocess, 75.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.2ms\n",
      "Speed: 1.1ms preprocess, 74.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 102.6ms\n",
      "Speed: 1.6ms preprocess, 102.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 microwave, 75.1ms\n",
      "Speed: 1.1ms preprocess, 75.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.0ms\n",
      "Speed: 1.2ms preprocess, 75.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.3ms\n",
      "Speed: 1.2ms preprocess, 74.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 microwave, 75.1ms\n",
      "Speed: 1.1ms preprocess, 75.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 microwave, 75.6ms\n",
      "Speed: 1.2ms preprocess, 75.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.8ms\n",
      "Speed: 1.0ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.8ms\n",
      "Speed: 1.3ms preprocess, 73.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.8ms\n",
      "Speed: 1.1ms preprocess, 76.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.9ms\n",
      "Speed: 1.1ms preprocess, 73.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 77.2ms\n",
      "Speed: 1.0ms preprocess, 77.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 microwave, 73.6ms\n",
      "Speed: 1.5ms preprocess, 73.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.7ms\n",
      "Speed: 1.3ms preprocess, 73.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.8ms\n",
      "Speed: 1.4ms preprocess, 75.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.6ms\n",
      "Speed: 1.6ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.7ms\n",
      "Speed: 1.2ms preprocess, 75.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.6ms\n",
      "Speed: 1.3ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.5ms\n",
      "Speed: 1.3ms preprocess, 74.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.8ms\n",
      "Speed: 1.4ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.2ms\n",
      "Speed: 1.3ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.8ms\n",
      "Speed: 1.1ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 74.4ms\n",
      "Speed: 1.2ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 72.9ms\n",
      "Speed: 1.1ms preprocess, 72.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 75.0ms\n",
      "Speed: 1.2ms preprocess, 75.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 76.0ms\n",
      "Speed: 2.3ms preprocess, 76.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.6ms\n",
      "Speed: 1.0ms preprocess, 73.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.4ms\n",
      "Speed: 1.1ms preprocess, 75.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.1ms\n",
      "Speed: 1.5ms preprocess, 76.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 1.3ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.0ms\n",
      "Speed: 2.1ms preprocess, 75.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.1ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.8ms\n",
      "Speed: 1.3ms preprocess, 76.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.7ms\n",
      "Speed: 1.2ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.3ms\n",
      "Speed: 1.3ms preprocess, 95.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.8ms\n",
      "Speed: 1.8ms preprocess, 105.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 80.4ms\n",
      "Speed: 1.0ms preprocess, 80.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 76.0ms\n",
      "Speed: 1.1ms preprocess, 76.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.3ms\n",
      "Speed: 1.1ms preprocess, 75.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.4ms\n",
      "Speed: 1.4ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.4ms\n",
      "Speed: 1.3ms preprocess, 79.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 92.7ms\n",
      "Speed: 1.2ms preprocess, 92.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 236.2ms\n",
      "Speed: 1.3ms preprocess, 236.2ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 380.3ms\n",
      "Speed: 11.9ms preprocess, 380.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 111.2ms\n",
      "Speed: 2.3ms preprocess, 111.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 106.7ms\n",
      "Speed: 1.5ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 121.8ms\n",
      "Speed: 1.2ms preprocess, 121.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.7ms\n",
      "Speed: 1.2ms preprocess, 116.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 106.0ms\n",
      "Speed: 1.4ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 107.8ms\n",
      "Speed: 1.1ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 102.1ms\n",
      "Speed: 1.5ms preprocess, 102.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 100.0ms\n",
      "Speed: 1.3ms preprocess, 100.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 188.3ms\n",
      "Speed: 1.5ms preprocess, 188.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 118.3ms\n",
      "Speed: 1.5ms preprocess, 118.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.5ms\n",
      "Speed: 1.3ms preprocess, 120.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 159.8ms\n",
      "Speed: 2.1ms preprocess, 159.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 refrigerator, 127.8ms\n",
      "Speed: 1.4ms preprocess, 127.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 123.4ms\n",
      "Speed: 1.5ms preprocess, 123.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 122.7ms\n",
      "Speed: 1.5ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 127.0ms\n",
      "Speed: 1.4ms preprocess, 127.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 112.9ms\n",
      "Speed: 1.2ms preprocess, 112.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 111.5ms\n",
      "Speed: 1.6ms preprocess, 111.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 117.0ms\n",
      "Speed: 3.3ms preprocess, 117.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 115.0ms\n",
      "Speed: 2.2ms preprocess, 115.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 106.2ms\n",
      "Speed: 1.4ms preprocess, 106.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 110.5ms\n",
      "Speed: 1.3ms preprocess, 110.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 113.3ms\n",
      "Speed: 1.4ms preprocess, 113.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 117.8ms\n",
      "Speed: 1.6ms preprocess, 117.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 132.6ms\n",
      "Speed: 1.6ms preprocess, 132.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.7ms\n",
      "Speed: 1.4ms preprocess, 123.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.8ms\n",
      "Speed: 1.8ms preprocess, 121.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.2ms\n",
      "Speed: 2.7ms preprocess, 117.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 120.8ms\n",
      "Speed: 1.6ms preprocess, 120.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 117.6ms\n",
      "Speed: 1.3ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 107.2ms\n",
      "Speed: 2.0ms preprocess, 107.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 129.9ms\n",
      "Speed: 1.5ms preprocess, 129.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.4ms\n",
      "Speed: 1.7ms preprocess, 116.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 114.2ms\n",
      "Speed: 2.9ms preprocess, 114.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 156.8ms\n",
      "Speed: 3.8ms preprocess, 156.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 373.1ms\n",
      "Speed: 3.6ms preprocess, 373.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 86.7ms\n",
      "Speed: 1.1ms preprocess, 86.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.3ms\n",
      "Speed: 1.7ms preprocess, 87.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.9ms\n",
      "Speed: 1.4ms preprocess, 90.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.5ms\n",
      "Speed: 1.2ms preprocess, 96.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.3ms\n",
      "Speed: 1.2ms preprocess, 91.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.9ms\n",
      "Speed: 1.4ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.1ms\n",
      "Speed: 1.3ms preprocess, 78.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.1ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.2ms\n",
      "Speed: 1.4ms preprocess, 74.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.4ms\n",
      "Speed: 1.2ms preprocess, 104.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.5ms\n",
      "Speed: 1.2ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.0ms\n",
      "Speed: 1.2ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.1ms\n",
      "Speed: 1.3ms preprocess, 86.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.9ms\n",
      "Speed: 1.3ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 78.9ms\n",
      "Speed: 1.4ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 keyboard, 75.3ms\n",
      "Speed: 1.1ms preprocess, 75.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 keyboard, 79.9ms\n",
      "Speed: 1.5ms preprocess, 79.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 96.9ms\n",
      "Speed: 1.2ms preprocess, 96.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 94.0ms\n",
      "Speed: 1.5ms preprocess, 94.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 90.5ms\n",
      "Speed: 1.1ms preprocess, 90.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 77.3ms\n",
      "Speed: 1.5ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 83.3ms\n",
      "Speed: 1.1ms preprocess, 83.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 keyboard, 79.4ms\n",
      "Speed: 1.3ms preprocess, 79.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.6ms\n",
      "Speed: 1.5ms preprocess, 78.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 75.9ms\n",
      "Speed: 1.2ms preprocess, 75.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.1ms preprocess, 75.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.1ms\n",
      "Speed: 1.3ms preprocess, 76.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.1ms\n",
      "Speed: 1.1ms preprocess, 73.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.1ms\n",
      "Speed: 1.8ms preprocess, 81.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.7ms\n",
      "Speed: 1.3ms preprocess, 74.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 74.8ms\n",
      "Speed: 1.4ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 1.3ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.6ms\n",
      "Speed: 1.2ms preprocess, 88.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 84.9ms\n",
      "Speed: 1.3ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.1ms\n",
      "Speed: 1.3ms preprocess, 80.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 1.3ms preprocess, 75.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.6ms\n",
      "Speed: 1.2ms preprocess, 76.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.1ms\n",
      "Speed: 1.1ms preprocess, 75.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.5ms preprocess, 76.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 1.1ms preprocess, 76.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 1.1ms preprocess, 76.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 75.1ms\n",
      "Speed: 1.5ms preprocess, 75.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.1ms\n",
      "Speed: 1.1ms preprocess, 79.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.0ms\n",
      "Speed: 1.4ms preprocess, 77.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 1.1ms preprocess, 74.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.4ms\n",
      "Speed: 1.1ms preprocess, 75.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Speed: 1.1ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.8ms\n",
      "Speed: 1.2ms preprocess, 76.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.0ms\n",
      "Speed: 1.2ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.3ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 74.6ms\n",
      "Speed: 1.2ms preprocess, 74.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 79.2ms\n",
      "Speed: 1.4ms preprocess, 79.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.1ms\n",
      "Speed: 1.3ms preprocess, 75.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 322.8ms\n",
      "Speed: 1.1ms preprocess, 322.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.7ms\n",
      "Speed: 1.5ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.5ms\n",
      "Speed: 1.3ms preprocess, 77.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 97.2ms\n",
      "Speed: 1.2ms preprocess, 97.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.8ms\n",
      "Speed: 1.5ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 1.4ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.3ms\n",
      "Speed: 1.2ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.8ms\n",
      "Speed: 1.3ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.9ms\n",
      "Speed: 1.4ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.2ms\n",
      "Speed: 1.3ms preprocess, 78.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 83.3ms\n",
      "Speed: 1.2ms preprocess, 83.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.1ms\n",
      "Speed: 1.7ms preprocess, 110.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 116.7ms\n",
      "Speed: 1.2ms preprocess, 116.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 154.0ms\n",
      "Speed: 1.8ms preprocess, 154.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 152.6ms\n",
      "Speed: 1.6ms preprocess, 152.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 135.8ms\n",
      "Speed: 1.4ms preprocess, 135.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 155.1ms\n",
      "Speed: 1.2ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 143.8ms\n",
      "Speed: 1.3ms preprocess, 143.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.5ms\n",
      "Speed: 1.8ms preprocess, 231.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.2ms\n",
      "Speed: 1.2ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.8ms\n",
      "Speed: 1.2ms preprocess, 114.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.9ms\n",
      "Speed: 1.5ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 134.5ms\n",
      "Speed: 1.8ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 133.6ms\n",
      "Speed: 1.5ms preprocess, 133.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 143.8ms\n",
      "Speed: 2.1ms preprocess, 143.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 276.5ms\n",
      "Speed: 2.0ms preprocess, 276.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 96.0ms\n",
      "Speed: 1.4ms preprocess, 96.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 92.7ms\n",
      "Speed: 1.1ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 239.5ms\n",
      "Speed: 1.5ms preprocess, 239.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 145.8ms\n",
      "Speed: 25.0ms preprocess, 145.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.9ms\n",
      "Speed: 1.2ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.6ms\n",
      "Speed: 1.4ms preprocess, 85.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 106.3ms\n",
      "Speed: 1.1ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.6ms\n",
      "Speed: 1.3ms preprocess, 130.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.5ms\n",
      "Speed: 2.2ms preprocess, 113.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.1ms\n",
      "Speed: 1.7ms preprocess, 121.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.0ms\n",
      "Speed: 1.2ms preprocess, 108.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.4ms\n",
      "Speed: 1.6ms preprocess, 98.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.2ms\n",
      "Speed: 1.4ms preprocess, 103.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.9ms\n",
      "Speed: 1.2ms preprocess, 98.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 94.1ms\n",
      "Speed: 1.2ms preprocess, 94.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 186.4ms\n",
      "Speed: 1.4ms preprocess, 186.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 139.9ms\n",
      "Speed: 1.9ms preprocess, 139.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.3ms\n",
      "Speed: 1.8ms preprocess, 102.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 109.7ms\n",
      "Speed: 1.6ms preprocess, 109.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.3ms\n",
      "Speed: 1.8ms preprocess, 109.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.5ms\n",
      "Speed: 1.3ms preprocess, 103.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 112.0ms\n",
      "Speed: 1.1ms preprocess, 112.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 199.0ms\n",
      "Speed: 1.8ms preprocess, 199.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 85.2ms\n",
      "Speed: 3.2ms preprocess, 85.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.2ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 1.5ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 1.1ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.4ms preprocess, 75.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.3ms preprocess, 76.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.8ms\n",
      "Speed: 1.4ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.3ms\n",
      "Speed: 1.1ms preprocess, 88.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.6ms\n",
      "Speed: 1.3ms preprocess, 78.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.5ms\n",
      "Speed: 1.6ms preprocess, 80.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.9ms\n",
      "Speed: 1.4ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.0ms\n",
      "Speed: 2.5ms preprocess, 87.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.2ms\n",
      "Speed: 1.2ms preprocess, 86.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 85.4ms\n",
      "Speed: 1.3ms preprocess, 85.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 1.2ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.4ms\n",
      "Speed: 1.2ms preprocess, 82.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.0ms\n",
      "Speed: 1.3ms preprocess, 82.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.5ms\n",
      "Speed: 1.1ms preprocess, 75.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.6ms\n",
      "Speed: 2.9ms preprocess, 81.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 1.2ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.9ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.9ms\n",
      "Speed: 1.5ms preprocess, 77.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.3ms preprocess, 76.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.8ms\n",
      "Speed: 1.6ms preprocess, 83.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 81.7ms\n",
      "Speed: 1.2ms preprocess, 81.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 79.0ms\n",
      "Speed: 1.2ms preprocess, 79.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 1.2ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.8ms\n",
      "Speed: 1.5ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.3ms\n",
      "Speed: 1.9ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.9ms\n",
      "Speed: 1.2ms preprocess, 75.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.2ms\n",
      "Speed: 1.4ms preprocess, 75.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.7ms\n",
      "Speed: 1.4ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.2ms\n",
      "Speed: 1.3ms preprocess, 74.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.9ms\n",
      "Speed: 1.1ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 85.5ms\n",
      "Speed: 1.3ms preprocess, 85.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 95.2ms\n",
      "Speed: 1.6ms preprocess, 95.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 75.9ms\n",
      "Speed: 1.2ms preprocess, 75.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 2.0ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.8ms\n",
      "Speed: 1.4ms preprocess, 77.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.1ms\n",
      "Speed: 1.2ms preprocess, 78.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.5ms\n",
      "Speed: 1.2ms preprocess, 78.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 1.4ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.3ms\n",
      "Speed: 1.3ms preprocess, 79.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 1.2ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.5ms\n",
      "Speed: 1.1ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.2ms\n",
      "Speed: 1.3ms preprocess, 77.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.8ms\n",
      "Speed: 1.4ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.3ms preprocess, 76.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.8ms\n",
      "Speed: 1.2ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.9ms\n",
      "Speed: 1.5ms preprocess, 83.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.5ms\n",
      "Speed: 1.5ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.1ms\n",
      "Speed: 1.7ms preprocess, 77.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 81.8ms\n",
      "Speed: 1.2ms preprocess, 81.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.5ms\n",
      "Speed: 1.1ms preprocess, 78.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.9ms\n",
      "Speed: 1.1ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.8ms\n",
      "Speed: 1.3ms preprocess, 78.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.5ms\n",
      "Speed: 1.5ms preprocess, 75.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.3ms\n",
      "Speed: 2.0ms preprocess, 86.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.5ms\n",
      "Speed: 1.2ms preprocess, 77.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.5ms\n",
      "Speed: 1.4ms preprocess, 100.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.8ms\n",
      "Speed: 1.4ms preprocess, 76.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.9ms\n",
      "Speed: 1.5ms preprocess, 75.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 79.7ms\n",
      "Speed: 2.6ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.4ms\n",
      "Speed: 1.1ms preprocess, 77.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.9ms\n",
      "Speed: 1.1ms preprocess, 88.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.7ms\n",
      "Speed: 1.1ms preprocess, 75.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 1.4ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.4ms\n",
      "Speed: 1.2ms preprocess, 77.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 79.4ms\n",
      "Speed: 1.2ms preprocess, 79.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.3ms\n",
      "Speed: 1.3ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.9ms\n",
      "Speed: 1.4ms preprocess, 75.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.7ms\n",
      "Speed: 1.3ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 79.7ms\n",
      "Speed: 1.4ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.2ms\n",
      "Speed: 1.5ms preprocess, 78.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.8ms\n",
      "Speed: 1.2ms preprocess, 77.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 87.5ms\n",
      "Speed: 1.1ms preprocess, 87.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 79.3ms\n",
      "Speed: 1.3ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.3ms\n",
      "Speed: 1.3ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.3ms\n",
      "Speed: 1.4ms preprocess, 79.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 84.5ms\n",
      "Speed: 1.2ms preprocess, 84.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.8ms\n",
      "Speed: 1.1ms preprocess, 77.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.2ms preprocess, 81.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.4ms\n",
      "Speed: 1.6ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 76.3ms\n",
      "Speed: 1.2ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 74.1ms\n",
      "Speed: 1.2ms preprocess, 74.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.8ms\n",
      "Speed: 1.3ms preprocess, 76.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.0ms\n",
      "Speed: 1.3ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.1ms preprocess, 81.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.3ms\n",
      "Speed: 1.2ms preprocess, 85.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.1ms\n",
      "Speed: 1.1ms preprocess, 87.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.0ms\n",
      "Speed: 1.7ms preprocess, 80.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.1ms\n",
      "Speed: 1.6ms preprocess, 79.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.4ms\n",
      "Speed: 1.5ms preprocess, 78.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.3ms\n",
      "Speed: 1.2ms preprocess, 84.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 1.6ms preprocess, 76.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.8ms\n",
      "Speed: 1.4ms preprocess, 85.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.1ms\n",
      "Speed: 1.1ms preprocess, 89.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.4ms\n",
      "Speed: 1.5ms preprocess, 86.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.0ms\n",
      "Speed: 1.4ms preprocess, 80.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.6ms preprocess, 76.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.2ms\n",
      "Speed: 1.2ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.2ms\n",
      "Speed: 1.3ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.6ms\n",
      "Speed: 1.2ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 81.1ms\n",
      "Speed: 1.2ms preprocess, 81.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cat, 77.4ms\n",
      "Speed: 1.2ms preprocess, 77.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 1.3ms preprocess, 77.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.0ms\n",
      "Speed: 1.2ms preprocess, 77.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.9ms\n",
      "Speed: 1.3ms preprocess, 82.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 77.4ms\n",
      "Speed: 1.3ms preprocess, 77.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.4ms\n",
      "Speed: 1.2ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.8ms\n",
      "Speed: 1.2ms preprocess, 76.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.9ms\n",
      "Speed: 1.3ms preprocess, 78.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cat, 1 tv, 80.7ms\n",
      "Speed: 1.5ms preprocess, 80.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 76.6ms\n",
      "Speed: 1.2ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.2ms\n",
      "Speed: 1.1ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.4ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.2ms\n",
      "Speed: 1.2ms preprocess, 78.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.5ms\n",
      "Speed: 1.5ms preprocess, 79.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 1.2ms preprocess, 78.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.6ms\n",
      "Speed: 1.1ms preprocess, 80.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.0ms\n",
      "Speed: 1.4ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 77.4ms\n",
      "Speed: 1.4ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.3ms\n",
      "Speed: 1.3ms preprocess, 78.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.5ms\n",
      "Speed: 1.2ms preprocess, 75.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.5ms\n",
      "Speed: 1.5ms preprocess, 78.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 78.5ms\n",
      "Speed: 1.2ms preprocess, 78.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.4ms\n",
      "Speed: 1.4ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 81.3ms\n",
      "Speed: 1.2ms preprocess, 81.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.8ms\n",
      "Speed: 1.3ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 1.1ms preprocess, 78.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.2ms\n",
      "Speed: 1.1ms preprocess, 79.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.4ms\n",
      "Speed: 1.2ms preprocess, 78.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 76.6ms\n",
      "Speed: 1.1ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.8ms\n",
      "Speed: 1.3ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 1.6ms preprocess, 78.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 83.1ms\n",
      "Speed: 1.9ms preprocess, 83.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.6ms\n",
      "Speed: 1.3ms preprocess, 76.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 77.7ms\n",
      "Speed: 1.2ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 76.5ms\n",
      "Speed: 1.3ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 79.0ms\n",
      "Speed: 1.5ms preprocess, 79.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 78.3ms\n",
      "Speed: 1.2ms preprocess, 78.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 82.4ms\n",
      "Speed: 1.4ms preprocess, 82.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 78.5ms\n",
      "Speed: 1.2ms preprocess, 78.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 104.6ms\n",
      "Speed: 1.5ms preprocess, 104.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 84.8ms\n",
      "Speed: 1.2ms preprocess, 84.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 79.6ms\n",
      "Speed: 1.5ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 85.4ms\n",
      "Speed: 1.6ms preprocess, 85.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 81.5ms\n",
      "Speed: 1.7ms preprocess, 81.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 79.7ms\n",
      "Speed: 1.4ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 74.8ms\n",
      "Speed: 1.3ms preprocess, 74.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 80.0ms\n",
      "Speed: 1.2ms preprocess, 80.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.5ms preprocess, 81.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 77.9ms\n",
      "Speed: 1.2ms preprocess, 77.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 80.0ms\n",
      "Speed: 1.4ms preprocess, 80.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.8ms\n",
      "Speed: 1.2ms preprocess, 79.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.9ms\n",
      "Speed: 1.1ms preprocess, 76.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 81.6ms\n",
      "Speed: 1.4ms preprocess, 81.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 79.3ms\n",
      "Speed: 1.5ms preprocess, 79.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.0ms\n",
      "Speed: 1.2ms preprocess, 77.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 78.2ms\n",
      "Speed: 1.4ms preprocess, 78.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 78.7ms\n",
      "Speed: 1.2ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 77.3ms\n",
      "Speed: 1.1ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 77.3ms\n",
      "Speed: 1.4ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 80.9ms\n",
      "Speed: 1.2ms preprocess, 80.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 79.6ms\n",
      "Speed: 1.3ms preprocess, 79.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 76.3ms\n",
      "Speed: 1.7ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 78.0ms\n",
      "Speed: 1.3ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 76.7ms\n",
      "Speed: 1.3ms preprocess, 76.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 77.2ms\n",
      "Speed: 1.2ms preprocess, 77.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 80.2ms\n",
      "Speed: 1.3ms preprocess, 80.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 81.4ms\n",
      "Speed: 1.2ms preprocess, 81.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 78.0ms\n",
      "Speed: 1.2ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 77.4ms\n",
      "Speed: 1.5ms preprocess, 77.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 78.7ms\n",
      "Speed: 1.1ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 76.9ms\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 78.1ms\n",
      "Speed: 1.2ms preprocess, 78.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 76.9ms\n",
      "Speed: 1.1ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 80.9ms\n",
      "Speed: 1.2ms preprocess, 80.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 86.7ms\n",
      "Speed: 1.4ms preprocess, 86.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 92.2ms\n",
      "Speed: 2.0ms preprocess, 92.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 76.2ms\n",
      "Speed: 1.6ms preprocess, 76.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 77.3ms\n",
      "Speed: 1.5ms preprocess, 77.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 77.9ms\n",
      "Speed: 1.3ms preprocess, 77.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 77.4ms\n",
      "Speed: 1.2ms preprocess, 77.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 81.5ms\n",
      "Speed: 1.3ms preprocess, 81.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 remote, 77.3ms\n",
      "Speed: 1.2ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 78.7ms\n",
      "Speed: 1.3ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 83.8ms\n",
      "Speed: 1.3ms preprocess, 83.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 85.9ms\n",
      "Speed: 1.2ms preprocess, 85.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 79.1ms\n",
      "Speed: 1.7ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 76.6ms\n",
      "Speed: 1.2ms preprocess, 76.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 77.3ms\n",
      "Speed: 1.5ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 80.3ms\n",
      "Speed: 1.4ms preprocess, 80.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 remote, 79.1ms\n",
      "Speed: 1.6ms preprocess, 79.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 2 remotes, 86.4ms\n",
      "Speed: 1.8ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 79.4ms\n",
      "Speed: 1.4ms preprocess, 79.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 81.7ms\n",
      "Speed: 1.2ms preprocess, 81.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.1ms\n",
      "Speed: 1.4ms preprocess, 77.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.1ms\n",
      "Speed: 1.3ms preprocess, 77.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 82.0ms\n",
      "Speed: 1.2ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.1ms\n",
      "Speed: 1.6ms preprocess, 78.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.4ms\n",
      "Speed: 1.3ms preprocess, 78.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.8ms\n",
      "Speed: 1.2ms preprocess, 76.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 80.8ms\n",
      "Speed: 1.6ms preprocess, 80.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.7ms\n",
      "Speed: 1.8ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 76.9ms\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.4ms preprocess, 76.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.8ms\n",
      "Speed: 2.2ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.9ms\n",
      "Speed: 1.2ms preprocess, 77.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.2ms\n",
      "Speed: 1.4ms preprocess, 78.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 1.3ms preprocess, 76.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.1ms\n",
      "Speed: 1.3ms preprocess, 77.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.4ms\n",
      "Speed: 1.7ms preprocess, 78.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.0ms\n",
      "Speed: 1.1ms preprocess, 83.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.5ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.7ms\n",
      "Speed: 1.6ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.4ms\n",
      "Speed: 1.5ms preprocess, 83.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.0ms\n",
      "Speed: 1.2ms preprocess, 79.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.0ms\n",
      "Speed: 1.4ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.0ms\n",
      "Speed: 1.3ms preprocess, 78.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.6ms\n",
      "Speed: 1.5ms preprocess, 80.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 79.3ms\n",
      "Speed: 1.1ms preprocess, 79.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.6ms\n",
      "Speed: 1.2ms preprocess, 78.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 1.1ms preprocess, 76.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.9ms\n",
      "Speed: 1.6ms preprocess, 81.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv8 model (e.g., small version)\n",
    "model = YOLO(\"yolov8s.pt\")  # or 'yolov8n.pt', 'yolov8m.pt', etc.\n",
    "\n",
    "# Start the webcam\n",
    "cap = cv2.VideoCapture(0)  # 0 is the default webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference on the frame\n",
    "    results = model.predict(source=frame, show=False, conf=0.5)\n",
    "\n",
    "    # Draw results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Show the output\n",
    "    cv2.imshow(\"YOLOv8 - Real-Time Detection\", annotated_frame)\n",
    "\n",
    "    # Break on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release and close everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d76b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total images found: 1444\n",
      "\n",
      " Most common image resolutions:\n",
      "   (640, 640) - 1444 images\n",
      "\n",
      " Dataset check complete. 1444 images scanned.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your images folder\n",
    "image_dir = \"E-waste/valid/images\"\n",
    "\n",
    "# Supported image extensions\n",
    "image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\"]\n",
    "\n",
    "# Gather image file paths\n",
    "image_files = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "\n",
    "# Initialize stats\n",
    "image_count = len(image_files)\n",
    "dimensions = []\n",
    "\n",
    "print(f\" Total images found: {image_count}\")\n",
    "\n",
    "# Loop through and collect dimension info\n",
    "for img_file in image_files:\n",
    "    try:\n",
    "        with Image.open(os.path.join(image_dir, img_file)) as img:\n",
    "            dimensions.append(img.size)  # (width, height)\n",
    "    except Exception as e:\n",
    "        print(f\" Could not open {img_file}: {e}\")\n",
    "\n",
    "# Count resolution frequencies\n",
    "dim_counter = Counter(dimensions)\n",
    "most_common_dims = dim_counter.most_common(5)\n",
    "\n",
    "print(\"\\n Most common image resolutions:\")\n",
    "for dim, count in most_common_dims:\n",
    "    print(f\"   {dim} - {count} images\")\n",
    "\n",
    "print(f\"\\n Dataset check complete. {image_count} images scanned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fabbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total images: 4991\n",
      " Total label files: 4991\n",
      " Images with missing labels: 0\n",
      " Label files with no matching image: 0\n",
      "\n",
      " Class distribution (class_id: count):\n",
      "  21: 147 annotations\n",
      "  2: 136 annotations\n",
      "  30: 136 annotations\n",
      "  14: 145 annotations\n",
      "  18: 149 annotations\n",
      "  35: 134 annotations\n",
      "  29: 161 annotations\n",
      "  36: 172 annotations\n",
      "  0: 180 annotations\n",
      "  9: 151 annotations\n",
      "  10: 160 annotations\n",
      "  32: 142 annotations\n",
      "  11: 144 annotations\n",
      "  25: 167 annotations\n",
      "  15: 144 annotations\n",
      "  34: 134 annotations\n",
      "  28: 162 annotations\n",
      "  7: 145 annotations\n",
      "  22: 146 annotations\n",
      "  16: 145 annotations\n",
      "  4: 205 annotations\n",
      "  17: 150 annotations\n",
      "  13: 139 annotations\n",
      "  5: 145 annotations\n",
      "  24: 130 annotations\n",
      "  31: 189 annotations\n",
      "  26: 147 annotations\n",
      "  19: 151 annotations\n",
      "  27: 147 annotations\n",
      "  33: 162 annotations\n",
      "  8: 150 annotations\n",
      "  3: 143 annotations\n",
      "  6: 147 annotations\n",
      "  23: 142 annotations\n",
      "  12: 178 annotations\n",
      "  20: 134 annotations\n",
      "  1: 131 annotations\n",
      "\n",
      " Dataset label inspection complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "base_path = \"E-waste/train\"\n",
    "images_path = os.path.join(base_path, \"images\")\n",
    "labels_path = os.path.join(base_path, \"labels\")\n",
    "\n",
    "# Get list of image and label filenames (without extensions)\n",
    "image_files = [os.path.splitext(f)[0] for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "label_files = [os.path.splitext(f)[0] for f in os.listdir(labels_path) if f.endswith('.txt')]\n",
    "\n",
    "# Summary\n",
    "total_images = len(image_files)\n",
    "total_labels = len(label_files)\n",
    "\n",
    "# Check mismatches\n",
    "missing_labels = set(image_files) - set(label_files)\n",
    "orphan_labels = set(label_files) - set(image_files)\n",
    "\n",
    "print(f\" Total images: {total_images}\")\n",
    "print(f\" Total label files: {total_labels}\")\n",
    "print(f\" Images with missing labels: {len(missing_labels)}\")\n",
    "print(f\" Label files with no matching image: {len(orphan_labels)}\")\n",
    "\n",
    "if missing_labels:\n",
    "    print(\"\\nMissing label files for:\")\n",
    "    print(\"\\n\".join(list(missing_labels)[:5]))  # show top 5\n",
    "\n",
    "if orphan_labels:\n",
    "    print(\"\\nOrphan label files:\")\n",
    "    print(\"\\n\".join(list(orphan_labels)[:5]))  # show top 5\n",
    "\n",
    "# Analyze class distribution\n",
    "class_counter = Counter()\n",
    "for file in label_files:\n",
    "    label_path = os.path.join(labels_path, file + \".txt\")\n",
    "    try:\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                class_id = line.strip().split()[0]\n",
    "                class_counter[class_id] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {label_path}: {e}\")\n",
    "\n",
    "print(\"\\n Class distribution (class_id: count):\")\n",
    "for class_id, count in class_counter.items():\n",
    "    print(f\"  {class_id}: {count} annotations\")\n",
    "\n",
    "print(\"\\n Dataset label inspection complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453292ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Sort classes by count (optional)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m classes, counts = \u001b[38;5;28mzip\u001b[39m(*\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mclasses\u001b[49m, counts), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m], reverse=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[31mNameError\u001b[39m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort classes by count (optional)\n",
    "classes, counts = zip(*sorted(zip(classes, counts), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/y01h3w0s4sldyhwtlxfpx31c0000gn/T/ipykernel_78198/2377858428.py:47: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/Users/ujjwalraj/Desktop/Ewaste/yolov5-env/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Paths ---\n",
    "labels_path = \"E-waste-mini/valid/labels\"  # path to your YOLO labels\n",
    "yaml_path = \"E-waste-mini/custom.yaml\"             # path to your YAML file\n",
    "\n",
    "# --- Load class names from custom.yaml ---\n",
    "with open(yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    class_names = data['names']  # dictionary: {0: 'Battery', 1: 'Laptop', ..., 36: 'Smartwatch'}\n",
    "\n",
    "# --- Count class occurrences ---\n",
    "class_counter = Counter()\n",
    "\n",
    "for label_file in os.listdir(labels_path):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(labels_path, label_file), \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():  # skip empty lines\n",
    "                    class_id = int(line.strip().split()[0])\n",
    "                    class_counter[class_id] += 1\n",
    "\n",
    "# --- Prepare data for plot ---\n",
    "classes = [class_names[cid] for cid in class_counter.keys()]\n",
    "counts = [class_counter[cid] for cid in class_counter.keys()]\n",
    "\n",
    "# --- Optional: Sort by count (descending) ---\n",
    "classes, counts = zip(*sorted(zip(classes, counts), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars = plt.bar(classes, counts, color='skyblue')\n",
    "plt.title(\" E-waste Class Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Class Name\", fontsize=12)\n",
    "plt.ylabel(\"Number of Annotations\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, int(yval), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8c4cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/y01h3w0s4sldyhwtlxfpx31c0000gn/T/ipykernel_10924/1140225240.py:47: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Paths ---\n",
    "labels_path = \"E-waste/valid/labels\"  # path to your YOLO labels\n",
    "yaml_path = \"E-waste/custom.yaml\"             # path to your YAML file\n",
    "\n",
    "# --- Load class names from custom.yaml ---\n",
    "with open(yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    class_names = data['names']  # dictionary: {0: 'Battery', 1: 'Laptop', ..., 36: 'Smartwatch'}\n",
    "\n",
    "# --- Count class occurrences ---\n",
    "class_counter = Counter()\n",
    "\n",
    "for label_file in os.listdir(labels_path):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(labels_path, label_file), \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():  # skip empty lines\n",
    "                    class_id = int(line.strip().split()[0])\n",
    "                    class_counter[class_id] += 1\n",
    "\n",
    "# --- Prepare data for plot ---\n",
    "classes = [class_names[cid] for cid in class_counter.keys()]\n",
    "counts = [class_counter[cid] for cid in class_counter.keys()]\n",
    "\n",
    "# --- Optional: Sort by count (descending) ---\n",
    "classes, counts = zip(*sorted(zip(classes, counts), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars = plt.bar(classes, counts, color='skyblue')\n",
    "plt.title(\" E-waste Class Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Class Name\", fontsize=12)\n",
    "plt.ylabel(\"Number of Annotations\", fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, int(yval), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bf63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class-wise Annotation Counts in Training Dataset:\n",
      "\n",
      "Class ID   Class Name           Count     \n",
      "---------------------------------------------\n",
      "4          Mouse                205       \n",
      "31         Projector            189       \n",
      "0          Battery              180       \n",
      "12         Charger              178       \n",
      "36         Smartwatch           172       \n",
      "25         VacuumCleaner        167       \n",
      "28         Scanner              162       \n",
      "33         GameConsole          162       \n",
      "29         Modem                161       \n",
      "10         TV                   160       \n",
      "9          DVD                  151       \n",
      "19         Cable                151       \n",
      "17         Speaker              150       \n",
      "8          HardDrive            150       \n",
      "18         Camera               149       \n",
      "21         Tablet               147       \n",
      "26         Microwave            147       \n",
      "27         Toaster              147       \n",
      "6          Printer              147       \n",
      "22         PowerBank            146       \n",
      "14         AC                   145       \n",
      "7          Router               145       \n",
      "16         Refrigerator         145       \n",
      "5          Monitor              145       \n",
      "11         Remote               144       \n",
      "15         WashingMachine       144       \n",
      "3          Keyboard             143       \n",
      "32         FlashDrive           142       \n",
      "23         LED                  142       \n",
      "13         Fan                  139       \n",
      "2          Mobile               136       \n",
      "30         PSU                  136       \n",
      "35         GPS                  134       \n",
      "34         Motherboard          134       \n",
      "20         CPU                  134       \n",
      "1          Laptop               131       \n",
      "24         HairDryer            130       \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "# --- Paths ---\n",
    "labels_path = \"E-waste/train/labels\"  # path to your YOLO labels\n",
    "yaml_path = \"custom.yaml\"             # path to your YAML file\n",
    "\n",
    "# --- Load class names from custom.yaml ---\n",
    "with open(\"E-waste/custom.yaml\", 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    class_names = data['names']  # dictionary: {0: 'Battery', 1: 'Laptop', ..., 36: 'Smartwatch'}\n",
    "\n",
    "# --- Count class occurrences ---\n",
    "class_counter = Counter()\n",
    "\n",
    "for label_file in os.listdir(labels_path):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        with open(os.path.join(labels_path, label_file), \"r\") as f:\n",
    "            for line in f:\n",
    "                if line.strip():  # skip empty lines\n",
    "                    class_id = int(line.strip().split()[0])\n",
    "                    class_counter[class_id] += 1\n",
    "\n",
    "# --- Sort by count (descending) ---\n",
    "sorted_classes = sorted(class_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --- Print results ---\n",
    "print(\" Class-wise Annotation Counts in Training Dataset:\\n\")\n",
    "print(f\"{'Class ID':<10} {'Class Name':<20} {'Count':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for class_id, count in sorted_classes:\n",
    "    class_name = class_names[class_id]\n",
    "    print(f\"{class_id:<10} {class_name:<20} {count:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f44685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.107  Python-3.12.4 torch-2.6.0 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/ujjwalraj/Desktop/Ewaste/E-waste-mini/custom.yaml, epochs=10, time=None, patience=5, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n-ewaste10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/ujjwalraj/runs/detect/yolov8n-ewaste10\n",
      "Overriding model.yaml nc=80 with nc=37\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    758527  ultralytics.nn.modules.head.Detect           [37, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,018,063 parameters, 3,018,047 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/ujjwalraj/runs/detect/yolov8n-ewaste10', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ujjwalraj/Desktop/Ewaste/E-waste-mini/train/labels... 370 images, 0 backgrounds, 0 corrupt: 100%|| 370/370 [00:00<00:00, 3081.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ujjwalraj/Desktop/Ewaste/E-waste-mini/train/labels.cache\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 143, len(boxes) = 407. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ujjwalraj/Desktop/Ewaste/E-waste-mini/train/labels.cache... 370 images, 0 backgrounds, 0 corrupt: 100%|| 370/370 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Box and segment counts should be equal, but got len(segments) = 143, len(boxes) = 407. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/ujjwalraj/runs/detect/yolov8n-ewaste10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000244, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/ujjwalraj/runs/detect/yolov8n-ewaste10\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.9122        4.5      1.274          2        416: 100%|| 24/24 [01:10<00:00,  2.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:33<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/10         0G     0.7815      4.338      1.166          2        416: 100%|| 24/24 [01:15<00:00,  3.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:31<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407     0.0173     0.0838     0.0385     0.0364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/10         0G     0.7714      4.135      1.199          2        416: 100%|| 24/24 [01:28<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:34<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407     0.0579      0.473      0.125      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/10         0G     0.7411      3.898      1.176          2        416: 100%|| 24/24 [01:19<00:00,  3.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:35<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.776      0.158      0.239      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G     0.7673      3.712      1.187          2        416: 100%|| 24/24 [01:30<00:00,  3.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:37<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.512      0.313      0.307      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.7694      3.499      1.207          2        416: 100%|| 24/24 [01:37<00:00,  4.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:41<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.574      0.371      0.385      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.7501      3.335      1.147          2        416: 100%|| 24/24 [01:40<00:00,  4.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:44<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.569       0.44      0.471      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.7343      3.175      1.133          2        416: 100%|| 24/24 [01:56<00:00,  4.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:45<00:00,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.649      0.448      0.518      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.6798      3.103      1.131          2        416: 100%|| 24/24 [01:54<00:00,  4.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:39<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.682      0.483      0.543      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.6865      3.021      1.137          2        416: 100%|| 24/24 [01:31<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:36<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.681      0.496      0.559      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.363 hours.\n",
      "Optimizer stripped from /Users/ujjwalraj/runs/detect/yolov8n-ewaste10/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/ujjwalraj/runs/detect/yolov8n-ewaste10/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/ujjwalraj/runs/detect/yolov8n-ewaste10/weights/best.pt...\n",
      "Ultralytics 8.3.107  Python-3.12.4 torch-2.6.0 CPU (Apple M1)\n",
      "Model summary (fused): 72 layers, 3,012,863 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 12/12 [00:36<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        370        407      0.684      0.495      0.559      0.487\n",
      "               Battery         10         11      0.436      0.818       0.55      0.514\n",
      "                Laptop         10         10          1          0      0.157      0.135\n",
      "                Mobile         10         10          1          0     0.0232     0.0118\n",
      "              Keyboard         10         10      0.723        0.3      0.346      0.191\n",
      "                 Mouse         10         11          1          0      0.021     0.0176\n",
      "               Monitor         11         11      0.407      0.909      0.891      0.858\n",
      "               Printer         10         10          1      0.717      0.906      0.755\n",
      "                Router         10         10      0.706        0.9      0.878      0.807\n",
      "             HardDrive         10         10      0.872        0.3      0.685      0.569\n",
      "                   DVD         10         10      0.488        0.7        0.7      0.642\n",
      "                    TV         10         10      0.951        0.7      0.755      0.695\n",
      "                Remote         10         10      0.429        0.9      0.829      0.764\n",
      "               Charger         10         10      0.399        0.6      0.497      0.457\n",
      "                   Fan         10         10      0.849        0.9      0.874      0.839\n",
      "                    AC         10         12      0.443      0.583      0.473      0.371\n",
      "        WashingMachine         10         10      0.486        0.5      0.494      0.422\n",
      "          Refrigerator         10         10       0.45        0.6      0.604      0.518\n",
      "               Speaker         10         11      0.277      0.364      0.202      0.198\n",
      "                Camera         11         12      0.342      0.583      0.454      0.407\n",
      "                 Cable         11         13      0.723      0.769      0.774      0.622\n",
      "                   CPU         10         10      0.563        0.4      0.436      0.375\n",
      "                Tablet         11         11      0.754      0.559      0.742      0.707\n",
      "             PowerBank         10         12          1      0.496      0.669      0.638\n",
      "                   LED         10         11      0.893      0.818      0.861      0.717\n",
      "             HairDryer         10         10          1          0      0.248      0.194\n",
      "         VacuumCleaner         11         12      0.576      0.667      0.726      0.641\n",
      "             Microwave         10         10          1          0       0.27      0.226\n",
      "               Toaster         10         10      0.869        0.6      0.827      0.803\n",
      "               Scanner         10         15      0.367      0.267      0.331      0.285\n",
      "                 Modem         10         13      0.518      0.692      0.766      0.738\n",
      "                   PSU         10         10          1      0.366      0.428      0.355\n",
      "             Projector         10         16      0.951      0.312      0.444      0.359\n",
      "            FlashDrive         10         10      0.892        0.1      0.541      0.234\n",
      "           GameConsole         12         13      0.407      0.615      0.644      0.633\n",
      "           Motherboard         10         10      0.298        0.1      0.378      0.283\n",
      "                   GPS         10         10      0.546      0.723      0.745      0.636\n",
      "            Smartwatch         11         13      0.708      0.462      0.496      0.394\n",
      "Speed: 0.5ms preprocess, 92.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/ujjwalraj/runs/detect/yolov8n-ewaste10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x159759f70>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.037543,    0.037543,           0],\n",
       "       [    0.22222,     0.22222,     0.22222, ...,    0.076923,    0.076923,           0],\n",
       "       [   0.028736,    0.028736,    0.028736, ...,   0.0002993,  0.00014965,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,     0.15152,     0.15152,           0],\n",
       "       [          1,           1,           1, ...,    0.030675,    0.030675,           0],\n",
       "       [          1,           1,           1, ...,  0.00010088,  5.0438e-05,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.048246,    0.048246,    0.069846, ...,           0,           0,           0],\n",
       "       [   0.030441,    0.030448,    0.059833, ...,           0,           0,           0],\n",
       "       [   0.029412,     0.02951,    0.035619, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [   0.041152,     0.04116,    0.069472, ...,           0,           0,           0],\n",
       "       [   0.048662,    0.048674,     0.06903, ...,           0,           0,           0],\n",
       "       [   0.015363,    0.015385,    0.031741, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.024719,    0.024719,    0.036318, ...,           1,           1,           1],\n",
       "       [   0.015456,    0.015459,    0.030839, ...,           1,           1,           1],\n",
       "       [    0.01495,    0.015001,    0.018275, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [   0.021008,    0.021012,    0.035986, ...,           1,           1,           1],\n",
       "       [   0.024938,    0.024944,    0.035892, ...,           1,           1,           1],\n",
       "       [  0.0077519,   0.0077629,    0.016174, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,     0.90909, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [        0.9,         0.9,         0.7, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,         0.9, ...,           0,           0,           0],\n",
       "       [    0.84615,     0.84615,     0.84615, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.49397978088814076)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.51409,      0.1354,    0.011769,     0.19103,    0.017634,     0.85753,     0.75484,     0.80722,     0.56928,     0.64156,     0.69508,     0.76426,     0.45712,     0.83873,     0.37104,      0.4225,     0.51816,     0.19797,     0.40656,     0.62244,     0.37479,     0.70735,     0.63755,     0.71739,\n",
       "           0.19376,     0.64061,     0.22562,     0.80253,     0.28533,     0.73808,     0.35487,     0.35933,     0.23424,     0.63273,     0.28318,     0.63619,     0.39403])\n",
       "names: {0: 'Battery', 1: 'Laptop', 2: 'Mobile', 3: 'Keyboard', 4: 'Mouse', 5: 'Monitor', 6: 'Printer', 7: 'Router', 8: 'HardDrive', 9: 'DVD', 10: 'TV', 11: 'Remote', 12: 'Charger', 13: 'Fan', 14: 'AC', 15: 'WashingMachine', 16: 'Refrigerator', 17: 'Speaker', 18: 'Camera', 19: 'Cable', 20: 'CPU', 21: 'Tablet', 22: 'PowerBank', 23: 'LED', 24: 'HairDryer', 25: 'VacuumCleaner', 26: 'Microwave', 27: 'Toaster', 28: 'Scanner', 29: 'Modem', 30: 'PSU', 31: 'Projector', 32: 'FlashDrive', 33: 'GameConsole', 34: 'Motherboard', 35: 'GPS', 36: 'Smartwatch'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.6844312766156108), 'metrics/recall(B)': np.float64(0.49517023394710086), 'metrics/mAP50(B)': np.float64(0.5585480900710105), 'metrics/mAP50-95(B)': np.float64(0.48680552431226637), 'fitness': np.float64(0.49397978088814076)}\n",
       "save_dir: PosixPath('/Users/ujjwalraj/runs/detect/yolov8n-ewaste10')\n",
       "speed: {'preprocess': 0.5022365973894233, 'inference': 92.14277342150642, 'loss': 7.399192671417384e-05, 'postprocess': 0.5899147567893}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pre-trained YOLOv8 nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train on custom e-waste dataset\n",
    "model.train(\n",
    "    data='/Users/ujjwalraj/Desktop/Ewaste/E-waste-mini/custom.yaml',\n",
    "    epochs=10,\n",
    "    imgsz=416,\n",
    "    batch=16,\n",
    "    name='yolov8n-ewaste',\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515ca54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Press 'q' to quit\n",
      "\n",
      "0: 384x640 (no detections), 52.5ms\n",
      "Speed: 2.1ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.0ms\n",
      "Speed: 1.3ms preprocess, 50.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.4ms\n",
      "Speed: 1.7ms preprocess, 52.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.6ms\n",
      "Speed: 1.5ms preprocess, 56.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.3ms\n",
      "Speed: 1.4ms preprocess, 43.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 1.4ms preprocess, 46.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 67.6ms\n",
      "Speed: 1.3ms preprocess, 67.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.6ms\n",
      "Speed: 1.2ms preprocess, 43.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.5ms preprocess, 48.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 1.5ms preprocess, 45.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.0ms\n",
      "Speed: 1.4ms preprocess, 56.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.2ms preprocess, 46.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.5ms\n",
      "Speed: 1.3ms preprocess, 56.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 1.3ms preprocess, 47.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.3ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.1ms\n",
      "Speed: 1.3ms preprocess, 43.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.9ms\n",
      "Speed: 1.1ms preprocess, 44.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.9ms\n",
      "Speed: 1.2ms preprocess, 42.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 1.1ms preprocess, 45.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.1ms\n",
      "Speed: 1.4ms preprocess, 50.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 51.9ms\n",
      "Speed: 1.4ms preprocess, 51.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 1.4ms preprocess, 49.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.4ms preprocess, 48.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 1.8ms preprocess, 48.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 1.5ms preprocess, 46.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.0ms\n",
      "Speed: 1.4ms preprocess, 45.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 1.3ms preprocess, 46.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.3ms preprocess, 44.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.2ms preprocess, 44.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.4ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.4ms preprocess, 48.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.1ms\n",
      "Speed: 1.2ms preprocess, 50.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 1.2ms preprocess, 44.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.8ms\n",
      "Speed: 1.2ms preprocess, 45.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.5ms\n",
      "Speed: 1.3ms preprocess, 45.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.4ms\n",
      "Speed: 1.6ms preprocess, 49.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 58.7ms\n",
      "Speed: 1.2ms preprocess, 58.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.0ms\n",
      "Speed: 1.3ms preprocess, 53.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.1ms preprocess, 48.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.7ms\n",
      "Speed: 1.2ms preprocess, 41.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.4ms preprocess, 44.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.2ms preprocess, 46.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.7ms\n",
      "Speed: 1.3ms preprocess, 49.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.2ms preprocess, 48.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.5ms preprocess, 48.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 51.0ms\n",
      "Speed: 1.4ms preprocess, 51.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 1.3ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.0ms\n",
      "Speed: 1.9ms preprocess, 56.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.7ms\n",
      "Speed: 1.3ms preprocess, 49.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.8ms\n",
      "Speed: 1.2ms preprocess, 44.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 1.3ms preprocess, 45.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 1.4ms preprocess, 45.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.0ms\n",
      "Speed: 1.3ms preprocess, 49.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 1.1ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.9ms\n",
      "Speed: 1.6ms preprocess, 50.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.3ms\n",
      "Speed: 1.4ms preprocess, 52.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 1.2ms preprocess, 46.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.6ms\n",
      "Speed: 1.4ms preprocess, 52.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.4ms preprocess, 44.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 57.1ms\n",
      "Speed: 1.4ms preprocess, 57.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.0ms\n",
      "Speed: 1.5ms preprocess, 62.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 1.4ms preprocess, 49.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.8ms\n",
      "Speed: 1.4ms preprocess, 45.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 1.3ms preprocess, 46.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.8ms\n",
      "Speed: 1.3ms preprocess, 45.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.3ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.9ms\n",
      "Speed: 1.3ms preprocess, 44.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 1.2ms preprocess, 46.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 1.1ms preprocess, 47.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.1ms preprocess, 42.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.2ms preprocess, 40.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.2ms preprocess, 49.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 1.6ms preprocess, 48.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.3ms\n",
      "Speed: 21.2ms preprocess, 235.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.9ms\n",
      "Speed: 1.3ms preprocess, 41.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.4ms\n",
      "Speed: 1.1ms preprocess, 42.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.1ms preprocess, 32.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.2ms preprocess, 32.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 121.6ms\n",
      "Speed: 1.8ms preprocess, 121.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.2ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 62.5ms\n",
      "Speed: 1.5ms preprocess, 62.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.2ms\n",
      "Speed: 1.6ms preprocess, 168.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 1.1ms preprocess, 47.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.4ms\n",
      "Speed: 1.2ms preprocess, 43.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.0ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.1ms preprocess, 38.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.8ms\n",
      "Speed: 1.3ms preprocess, 35.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.3ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.2ms preprocess, 34.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.6ms\n",
      "Speed: 1.2ms preprocess, 37.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.2ms preprocess, 34.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.3ms preprocess, 35.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.0ms preprocess, 35.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.1ms preprocess, 37.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.2ms preprocess, 39.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.4ms\n",
      "Speed: 1.2ms preprocess, 44.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 1.2ms preprocess, 45.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 71.3ms\n",
      "Speed: 1.2ms preprocess, 71.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.8ms\n",
      "Speed: 1.5ms preprocess, 49.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.7ms\n",
      "Speed: 1.1ms preprocess, 41.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.2ms preprocess, 41.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.4ms\n",
      "Speed: 1.1ms preprocess, 43.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.0ms\n",
      "Speed: 1.3ms preprocess, 40.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.5ms\n",
      "Speed: 1.1ms preprocess, 41.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.0ms preprocess, 35.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.6ms preprocess, 42.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.3ms\n",
      "Speed: 1.1ms preprocess, 41.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 57.0ms\n",
      "Speed: 1.4ms preprocess, 57.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.1ms\n",
      "Speed: 1.2ms preprocess, 52.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.3ms preprocess, 46.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.4ms\n",
      "Speed: 1.2ms preprocess, 42.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.0ms\n",
      "Speed: 1.2ms preprocess, 40.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.4ms\n",
      "Speed: 1.1ms preprocess, 38.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.8ms\n",
      "Speed: 1.4ms preprocess, 42.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.6ms\n",
      "Speed: 1.1ms preprocess, 44.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.0ms\n",
      "Speed: 1.3ms preprocess, 41.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 1.2ms preprocess, 46.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.1ms preprocess, 42.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.1ms\n",
      "Speed: 1.1ms preprocess, 40.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.4ms preprocess, 40.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.9ms\n",
      "Speed: 1.2ms preprocess, 43.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.2ms\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.2ms preprocess, 40.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.1ms\n",
      "Speed: 1.4ms preprocess, 42.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.5ms\n",
      "Speed: 1.2ms preprocess, 40.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 54.0ms\n",
      "Speed: 1.2ms preprocess, 54.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.5ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.3ms preprocess, 37.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.4ms preprocess, 38.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.9ms\n",
      "Speed: 1.2ms preprocess, 40.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.2ms\n",
      "Speed: 1.2ms preprocess, 45.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.5ms\n",
      "Speed: 1.3ms preprocess, 37.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.9ms\n",
      "Speed: 1.1ms preprocess, 36.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.6ms\n",
      "Speed: 1.2ms preprocess, 39.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.2ms preprocess, 37.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.5ms\n",
      "Speed: 1.1ms preprocess, 49.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.2ms\n",
      "Speed: 1.1ms preprocess, 52.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 69.1ms\n",
      "Speed: 1.5ms preprocess, 69.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.1ms preprocess, 44.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.3ms\n",
      "Speed: 1.4ms preprocess, 44.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 1.2ms preprocess, 45.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.1ms preprocess, 44.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.3ms preprocess, 47.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.7ms\n",
      "Speed: 1.1ms preprocess, 49.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 57.9ms\n",
      "Speed: 1.0ms preprocess, 57.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.4ms\n",
      "Speed: 1.4ms preprocess, 44.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.2ms\n",
      "Speed: 1.2ms preprocess, 41.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.6ms\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.4ms preprocess, 47.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.4ms\n",
      "Speed: 1.5ms preprocess, 64.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 1.1ms preprocess, 47.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.4ms\n",
      "Speed: 1.2ms preprocess, 42.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.1ms preprocess, 40.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.0ms preprocess, 37.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.1ms preprocess, 35.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.1ms preprocess, 44.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.1ms preprocess, 38.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.4ms\n",
      "Speed: 1.3ms preprocess, 41.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 1.1ms preprocess, 39.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.4ms\n",
      "Speed: 1.1ms preprocess, 44.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.5ms preprocess, 40.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.1ms preprocess, 45.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.6ms\n",
      "Speed: 1.3ms preprocess, 44.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.0ms\n",
      "Speed: 1.1ms preprocess, 39.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.3ms\n",
      "Speed: 1.0ms preprocess, 44.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.4ms preprocess, 36.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.1ms preprocess, 37.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.2ms\n",
      "Speed: 1.2ms preprocess, 39.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.1ms preprocess, 40.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.3ms preprocess, 38.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.0ms preprocess, 36.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.1ms preprocess, 42.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.1ms preprocess, 38.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.2ms preprocess, 40.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.2ms\n",
      "Speed: 1.1ms preprocess, 45.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.1ms preprocess, 42.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.3ms\n",
      "Speed: 1.3ms preprocess, 37.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.2ms preprocess, 40.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.2ms preprocess, 37.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.1ms preprocess, 38.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.1ms preprocess, 37.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.0ms preprocess, 33.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.2ms preprocess, 33.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.2ms preprocess, 48.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.4ms preprocess, 37.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 1.4ms preprocess, 44.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.2ms preprocess, 34.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.1ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.4ms preprocess, 34.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.4ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.3ms preprocess, 41.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.4ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.1ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.1ms preprocess, 36.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.9ms\n",
      "Speed: 1.1ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 38.1ms\n",
      "Speed: 1.2ms preprocess, 38.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.2ms\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 36.0ms\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.0ms\n",
      "Speed: 1.3ms preprocess, 34.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 36.0ms\n",
      "Speed: 1.4ms preprocess, 36.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.4ms\n",
      "Speed: 1.4ms preprocess, 34.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.9ms\n",
      "Speed: 1.5ms preprocess, 34.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.8ms\n",
      "Speed: 2.4ms preprocess, 35.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.1ms\n",
      "Speed: 1.1ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 37.3ms\n",
      "Speed: 1.1ms preprocess, 37.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 40.4ms\n",
      "Speed: 1.2ms preprocess, 40.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 36.9ms\n",
      "Speed: 1.3ms preprocess, 36.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 33.7ms\n",
      "Speed: 1.3ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 33.1ms\n",
      "Speed: 1.1ms preprocess, 33.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.5ms\n",
      "Speed: 1.2ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.7ms\n",
      "Speed: 1.1ms preprocess, 35.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 33.7ms\n",
      "Speed: 1.4ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 computer keyboard, 35.2ms\n",
      "Speed: 1.2ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.5ms\n",
      "Speed: 1.5ms preprocess, 53.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.3ms preprocess, 35.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.4ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.3ms preprocess, 38.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.2ms preprocess, 34.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.1ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.1ms preprocess, 33.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.1ms preprocess, 37.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.2ms preprocess, 37.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.0ms preprocess, 36.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.1ms preprocess, 34.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.7ms\n",
      "Speed: 1.1ms preprocess, 36.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.7ms\n",
      "Speed: 1.2ms preprocess, 41.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.1ms preprocess, 34.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.4ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.1ms preprocess, 33.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.1ms preprocess, 34.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.3ms preprocess, 35.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.3ms preprocess, 33.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.3ms preprocess, 38.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.1ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.4ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.4ms preprocess, 38.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.1ms preprocess, 37.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.6ms\n",
      "Speed: 1.4ms preprocess, 36.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 40.1ms\n",
      "Speed: 1.2ms preprocess, 40.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.2ms preprocess, 33.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.1ms preprocess, 38.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 1.2ms preprocess, 45.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 1.6ms preprocess, 46.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.4ms preprocess, 35.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.5ms\n",
      "Speed: 5.5ms preprocess, 41.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.9ms\n",
      "Speed: 1.5ms preprocess, 37.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.5ms preprocess, 38.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.3ms preprocess, 37.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.2ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.2ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.1ms preprocess, 35.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.4ms preprocess, 36.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.1ms preprocess, 34.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.3ms\n",
      "Speed: 1.3ms preprocess, 50.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.3ms preprocess, 35.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.4ms\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.2ms\n",
      "Speed: 1.2ms preprocess, 39.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.2ms preprocess, 39.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.5ms preprocess, 35.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.3ms preprocess, 34.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.2ms preprocess, 39.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.2ms preprocess, 48.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.2ms preprocess, 37.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.8ms\n",
      "Speed: 1.5ms preprocess, 42.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.3ms preprocess, 34.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.3ms preprocess, 33.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.5ms preprocess, 35.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.2ms preprocess, 33.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.8ms\n",
      "Speed: 1.4ms preprocess, 44.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.3ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.2ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.1ms preprocess, 35.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 2.6ms preprocess, 36.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.3ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.1ms preprocess, 34.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.8ms\n",
      "Speed: 1.2ms preprocess, 35.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.8ms\n",
      "Speed: 1.1ms preprocess, 36.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.3ms preprocess, 34.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.2ms preprocess, 33.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.3ms preprocess, 35.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.0ms\n",
      "Speed: 1.3ms preprocess, 42.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.4ms preprocess, 35.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.1ms preprocess, 35.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.2ms preprocess, 36.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.4ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.2ms preprocess, 42.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.2ms preprocess, 34.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.2ms preprocess, 34.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.3ms preprocess, 34.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.2ms preprocess, 33.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.2ms preprocess, 32.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.1ms preprocess, 36.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.2ms preprocess, 35.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('/Users/ujjwalraj/runs/detect/yolov8n-ewaste10/weights/best.pt')\n",
    "\n",
    "# Open the webcam (0 = default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\" Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\" Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference on the frame\n",
    "    results = model.predict(source=frame, show=False, conf=0.5)\n",
    "\n",
    "    # Visualize results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Show the annotated frame\n",
    "    cv2.imshow(\"E-waste Detection\", annotated_frame)\n",
    "\n",
    "    # Quit when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
